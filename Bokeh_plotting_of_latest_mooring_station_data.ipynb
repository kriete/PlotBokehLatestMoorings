{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot bokeh graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create a bokeh representation of the latest data (incl. QC) from socib mooring stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib2 import Request, urlopen, URLError\n",
    "from lxml import html\n",
    "import time\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "import calendar\n",
    "from collections import OrderedDict\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.models import LinearAxis, Range1d, CustomJS\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.io import output_notebook, show, output_file, vplot, hplot\n",
    "import bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case, the output wants to be seen within the jupyter notebook, this line must be un-commented. However, since the generated HTML file will be opened in a new window, this is not really necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some basic data handling functions here. These will just enable us to e.g. access the nefCDF variable data as numpy array (significantly faster) or convert times to a joint base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_array(data_array):\n",
    "    if type(data_array.__array__()) is np.ma.masked_array:\n",
    "        return data_array.__array__().data\n",
    "    else:\n",
    "        return data_array.__array__()\n",
    "\n",
    "def get_qc_variable_name(variable):\n",
    "    try:\n",
    "        qc_variable_name = variable.ancillary_variables\n",
    "    except AttributeError:\n",
    "        # print \"No QC variable found for \" + variable.name\n",
    "        qc_variable_name = None\n",
    "    return qc_variable_name\n",
    "\n",
    "def get_pandas_timestamp_series(datetime_array):\n",
    "    out = pd.Series(np.zeros(len(datetime_array)))\n",
    "    counter = 0\n",
    "    for i in datetime_array:\n",
    "        out[counter] = pd.tslib.Timestamp(i)\n",
    "        counter += 1\n",
    "    return out\n",
    "    \n",
    "def days_to_seconds(days):\n",
    "    return int(days) * 24 * 60 * 60\n",
    "\n",
    "def get_str_time(x): return str(x)\n",
    "\n",
    "def totimestamp(dt, epoch=datetime.datetime(1970,1,1)):\n",
    "    td = dt - epoch\n",
    "    # return td.total_seconds()\n",
    "    return (td.microseconds + (td.seconds + td.days * 86400) * 10**6) / 10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these scripts differ from the socib mooring station report generation tool. Here, we use a simple web - scraping from the socib thredds server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mooring_stations(url):\n",
    "        name_list = []\n",
    "        end_URLBuilder = []\n",
    "        req = Request(url)\n",
    "        try:\n",
    "            response = urlopen(req)\n",
    "        except URLError as e:\n",
    "            if hasattr(e, 'reason'):\n",
    "                print 'We failed to reach a server.'\n",
    "                print 'Reason: ', e.reason\n",
    "            elif hasattr(e, 'code'):\n",
    "                print 'The server couldn\\'t fulfill the request.'\n",
    "                print 'Error code: ', e.code\n",
    "        else:\n",
    "            URLBuilder = []\n",
    "            tree = html.fromstring(response.read())\n",
    "            link_path = tree.xpath('//a')\n",
    "            for x in range(1, len(link_path)):\n",
    "                URLBuilder.append(link_path[x].values())\n",
    "            URLLister = []\n",
    "            for n in range(0, len(URLBuilder) - 4):\n",
    "                string = str(URLBuilder[n])\n",
    "                idx = string.find(\"/\")\n",
    "                url = \"http://thredds.socib.es/thredds/catalog/mooring/weather_station/\" + URLBuilder[n][0][0:idx - 1] + \"/L1/catalog.html\"\n",
    "                name = URLBuilder[n][0][0:idx - 2]\n",
    "                req = Request(url)\n",
    "                try:\n",
    "                    response = urlopen(req)\n",
    "                except URLError as e:\n",
    "                    if hasattr(e, 'reason'):\n",
    "                        print 'We failed to reach a server.'\n",
    "                        print 'Reason: ', e.reason\n",
    "                    elif hasattr(e, 'code'):\n",
    "                        print 'The server couldn\\'t fulfill the request.'\n",
    "                        print 'Error code: ', e.code\n",
    "                else:\n",
    "                    URLLister.append(url)\n",
    "                    name_list.append(name)\n",
    "\n",
    "            for m in URLLister:\n",
    "                req = Request(m)\n",
    "                try:\n",
    "                    response = urlopen(req)\n",
    "                except URLError as e:\n",
    "                    if hasattr(e, 'reason'):\n",
    "                        print 'We failed to reach a server.'\n",
    "                        print 'Reason: ', e.reason\n",
    "                    elif hasattr(e, 'code'):\n",
    "                        print 'The server couldn\\'t fulfill the request.'\n",
    "                        print 'Error code: ', e.code\n",
    "                else:\n",
    "                    tree = html.fromstring(response.read())\n",
    "                    link_path = tree.xpath('//a')\n",
    "                    for x in range(1, len(link_path)):\n",
    "                        string = str(link_path[x].values())\n",
    "                        idx = string.find(\"=\")\n",
    "                        end_URLBuilder.append(\"http://thredds.socib.es/thredds/dodsC/\" + str(\n",
    "                            link_path[x].values()[0][idx - 1:len(string)]))\n",
    "                        break\n",
    "            return name_list, end_URLBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define the bokeh plotting parameters. Also, we create a javascript callback to automatically adjust the y-axis according to the current zoom-extend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_data(links, desired_start_time, station_names):\n",
    "    global VARIABLES_OF_INTEREST\n",
    "    counter = 0\n",
    "    output_stations = []\n",
    "    for station in links:\n",
    "        root = Dataset(station)\n",
    "        time = get_data_array(root.variables[\"time\"])\n",
    "        idx = time >= desired_start_time\n",
    "        if not np.any(idx):\n",
    "            counter += 1\n",
    "            continue\n",
    "        variables = root.get_variables_by_attributes(standard_name=lambda n: n in VARIABLES_OF_INTEREST)\n",
    "        time = time[idx]\n",
    "        subplot =  []\n",
    "        variable_names = []\n",
    "        for v in variables:\n",
    "            try:\n",
    "                qc_data = get_data_array(root.variables[get_qc_variable_name(v)])\n",
    "                qc_data = qc_data[idx]\n",
    "                bad_idx = get_data_array(qc_data) != 1\n",
    "            except KeyError:\n",
    "                print \"No QC found for \" + v.name\n",
    "            v_name = v.name\n",
    "            variable_names.append(v_name)\n",
    "            v = get_data_array(v)\n",
    "            v = v[idx]\n",
    "            conv_time = get_pandas_timestamp_series([datetime.datetime.fromtimestamp(ts) for ts in time])\n",
    "            subplot.append(get_bokeh_grid_figure(v, qc_data, conv_time, station_names[counter]))\n",
    "            \n",
    "        sub_counter = 0\n",
    "        my_tabs = []\n",
    "        for sp in subplot:\n",
    "            my_tabs.append(Panel(child=sp, title=variable_names[sub_counter]))\n",
    "            sub_counter += 1\n",
    "        p = Tabs(tabs=my_tabs)\n",
    "        output_stations.append(p)\n",
    "        counter += 1\n",
    "    amount_stations = len(output_stations)\n",
    "    rest = amount_stations % 2\n",
    "    verticals = []\n",
    "    if amount_stations >= 2:\n",
    "        verticals.append(hplot(output_stations[0], output_stations[1]))\n",
    "    elif amount_stations == 1:\n",
    "        verticals.append(hplot(output_stations[0]))\n",
    "    else:\n",
    "        print(\"No stations to plot (PerformQC.draw_bokeh()).\")\n",
    "        return 1\n",
    "    for i in range(1, int(amount_stations/2)):\n",
    "        verticals.append(hplot(output_stations[i*2], output_stations[i*2+1]))\n",
    "    if rest > 0:\n",
    "        verticals.append(output_stations[-1])\n",
    "    show(vplot(*verticals))\n",
    "\n",
    "def get_bokeh_grid_figure(data, qc, converted_time, variable_name):\n",
    "        time_strings = map(get_str_time, converted_time)\n",
    "        hover = HoverTool(names=[\"data\"])\n",
    "        fig = figure(width=800, plot_height=300, title=variable_name, tools=[\"pan, box_zoom, xwheel_zoom, save, reset, resize\", hover], x_axis_type=\"datetime\")\n",
    "\n",
    "        source = ColumnDataSource(\n",
    "            data=dict(\n",
    "                time=time_strings,\n",
    "                data=data,\n",
    "                qc=qc\n",
    "            )\n",
    "        )\n",
    "        # data line\n",
    "        fig.line(converted_time, data, color=\"navy\", alpha=0.5, name=\"data\", source=source)\n",
    "        # data points\n",
    "        fig.square(converted_time, data, color=\"navy\", alpha=0.5)\n",
    "        fig.extra_y_ranges = {\"foo\": Range1d(start=0, end=10)}\n",
    "        fig.add_layout(LinearAxis(y_range_name=\"foo\"), 'right')\n",
    "        fig.line(converted_time, qc, color=\"green\", alpha=0.5, y_range_name=\"foo\")\n",
    "        jscode = \"\"\"\n",
    "                range.set('start', parseInt(%s));\n",
    "                range.set('end', parseInt(%s));\n",
    "                \"\"\"\n",
    "        fig.extra_y_ranges['foo'].callback = CustomJS(\n",
    "            args=dict(range=fig.extra_y_ranges['foo']),\n",
    "            code=jscode % (fig.extra_y_ranges['foo'].start,\n",
    "                           fig.extra_y_ranges['foo'].end)\n",
    "        )\n",
    "        pan_tool = fig.select(dict(type=bokeh.models.PanTool))\n",
    "        pan_tool.dimensions = [\"width\"]\n",
    "\n",
    "        hover = fig.select(dict(type=HoverTool))\n",
    "        hover.tooltips = OrderedDict([\n",
    "            ('time', '@time'),\n",
    "            ('value', '@data{0.0}'),\n",
    "            ('qc', '@qc')\n",
    "        ])\n",
    "\n",
    "        # check for ranges, if they are nan\n",
    "        if (np.isnan(np.nanmin(data)) & np.isnan(np.nanmax(data))) or (np.nanmin(data) == np.nanmax(data)):\n",
    "            bottom_y_range = 0\n",
    "            top_y_range = 10\n",
    "        else:\n",
    "            # add a 10% buffer to the max ranges\n",
    "            temp_min = np.nanmin(data)\n",
    "            temp_max = np.nanmax(data)\n",
    "            temp_diff = abs(temp_max-temp_min)\n",
    "            temp_thresh = round(temp_diff*0.1, 3)\n",
    "\n",
    "            bottom_y_range = temp_min - temp_thresh\n",
    "            top_y_range = temp_max + temp_thresh\n",
    "\n",
    "        fig.y_range = Range1d(bottom_y_range, top_y_range)\n",
    "        translate_time = converted_time.apply(lambda x: x.to_pydatetime())\n",
    "        converted_time_backward = map(totimestamp, translate_time)\n",
    "        source = ColumnDataSource({'x': converted_time_backward, 'y': data})\n",
    "\n",
    "        jscode = \"\"\"\n",
    "        function isNumeric(n) {\n",
    "          return !isNaN(parseFloat(n)) && isFinite(n);\n",
    "        }\n",
    "        var data = source.get('data');\n",
    "        var start = yrange.get('start');\n",
    "        var end = yrange.get('end');\n",
    "\n",
    "        var time_start = xrange.get('start')/1000;\n",
    "        var time_end = xrange.get('end')/1000;\n",
    "\n",
    "        var pre_max_old = end;\n",
    "        var pre_min_old = start;\n",
    "\n",
    "        var time = data['x'];\n",
    "        var pre = data['y'];\n",
    "        t_idx_start = time.filter(function(st){return st>=time_start})[0];\n",
    "        t_idx_start = time.indexOf(t_idx_start);\n",
    "\n",
    "        t_idx_end = time.filter(function(st){return st>=time_end})[0];\n",
    "        t_idx_end = time.indexOf(t_idx_end);\n",
    "\n",
    "        var pre_interval = pre.slice(t_idx_start, t_idx_end);\n",
    "        pre_interval = pre_interval.filter(function(st){return !isNaN(st)});\n",
    "        var pre_max = Math.max.apply(null, pre_interval);\n",
    "        var pre_min = Math.min.apply(null, pre_interval);\n",
    "        var ten_percent = (pre_max-pre_min)*0.1;\n",
    "\n",
    "        pre_max = pre_max + ten_percent;\n",
    "        pre_min = pre_min - ten_percent;\n",
    "\n",
    "        if((!isNumeric(pre_max)) || (!isNumeric(pre_min))) {\n",
    "            pre_max = pre_max_old;\n",
    "            pre_min = pre_min_old;\n",
    "        }\n",
    "\n",
    "        yrange.set('start', pre_min);\n",
    "        yrange.set('end', pre_max);\n",
    "        console.log(yrange.get('end'))\n",
    "\n",
    "        source.trigger('change');\n",
    "        \"\"\"\n",
    "\n",
    "        fig.y_range.callback = CustomJS(\n",
    "            args=dict(source=source, yrange=fig.y_range, xrange=fig.x_range), code=jscode)\n",
    "        fig.x_range.callback = CustomJS(\n",
    "            args=dict(source=source, yrange=fig.y_range, xrange=fig.x_range), code=jscode)\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we have to define the variables we want to plot. In this case, we just used the \"List of important parameters\" from the socib DataDiscovery service and added the relative humidity to it (since we will plot weather stations here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VARIABLES_OF_INTEREST = [\n",
    "          \"sea_water_temperature\",\n",
    "          \"air_temperature\",\n",
    "          \"sea_surface_wave_from_direction\",\n",
    "          \"sea_surface_wave_significant_height\",\n",
    "          \"wind_speed\",\n",
    "          \"wind_from_direction\",\n",
    "          \"wind_speed_of_gust\",\n",
    "          \"water_surface_height_above_reference_datum\",\n",
    "          \"air_pressure\",\n",
    "          \"sea_water_speed\",\n",
    "          \"direction_of_sea_water_velocity\",\n",
    "          \"sea_water_salinity\",\n",
    "          \"relative_humidity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get latest data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will call our defined methods. Also, we will define the output filename and the desired timespan of the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No QC found for WIN_DIR_GUS\n",
      "No QC found for WIN_DIR_GUS\n",
      "No QC found for WIN_DIR_GUS\n",
      "No QC found for WIN_DIR_GUS\n",
      "No QC found for WDIR_MAX\n"
     ]
    }
   ],
   "source": [
    "station_names, station_links = get_mooring_stations('http://thredds.socib.es/thredds/catalog/mooring/weather_station/catalog.html')\n",
    "# get latest x days\n",
    "\n",
    "days = 2\n",
    "html_file = 'bokeh_latest_data.html'\n",
    "\n",
    "seconds = days_to_seconds(days)\n",
    "dt = datetime.datetime.now()\n",
    "desired_start_time = calendar.timegm(dt.utctimetuple()) - seconds\n",
    "output_file(html_file)\n",
    "draw_data(station_links, desired_start_time, station_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
